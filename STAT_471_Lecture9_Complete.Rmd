---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

### **Hypothesis Testing in R**

There are many useful hypothesis tests that can be carried out in R. We'll look at some traditional tests along with some advanced hypothesis tests.

### Simple Hypothesis Tests for Proportions and Means

Simple hypothesis tests that we have seen before in elementary statistics can be carried out in R, such as for one sample proportions and one sample means. 

For proportions, let's test the hypothesis: \
H0: p = 0.5 \
HA: p != 0.5 \
with our sample probability of success being 0.62.

```{r}
binom.test(x = 62, n = 100, p = 0.5)
```
For many of these hypothesis tests, we use the default significance level of 0.05. However, you can modify the significance level by using conf.level. To change the alternative hypothesis, you can use the alternative parameter to "greater" or "less" for right and left tailed tests respectively.

```{r}
binom.test(x = 62, n = 100, p = 0.5, alternative = "greater", conf.level = 0.90)
```
The above is equivalent to testing the simple hypotheses at the 0.10 significance level: \
H0: p = 0.5 \
HA: p > 0.5 \
Note that with many of these hypothesis tests we cover, the corresponding confidence intervals are provided to you. 

For means, we can use a Z test when the population standard deviation is known or if the sample size is large enough (typically n >= 30 is a traditional rule that is widely used). We can use a T test with small sample sizes or when the population standard deviation is unknown. The test statistic for a Z test follows a standard normal distribution and a t test follows a t distribution.

Note that due to there being no built-in function for a Z test, we will carry this out using a handy package called BSDA.

```{r}
# Z test

# Generate some synthetic data first.

set.seed(42)
x = rnorm(30, mean = 100, sd = 20)
mean(x)

# install.packages("BSDA")
library(BSDA)

res = z.test(x, mu = 105, sigma.x = 20, alternative = "two.sided")
res
```
The above tests: \
H0: mu = 105 \
HA: mu != 105 \

Now let's see an example of a one sample T test in R.

Suppose that we have collected the weights of turtles and store them in a vector. 

```{r}
# T test

weights = c(301, 305, 312, 315, 318, 319, 310, 305, 313, 305, 305, 305)

t_test_weights = t.test(x = weights, mu = 310)
t_test_weights
```
<br>

### T Test for Comparison of Means

The Welch/Student T test for comparison of means can be ideal for comparing two-sample means. The test statistic follows a t-distribution.

Here for a two-tailed test, we test the hypotheses: \
H0: Mu1 = Mu2 (similarly, Mu1 - Mu2 = 0) \
HA: Mu1 != Mu2 \

```{r}
sample1 = c(310, 311, 310, 315, 311, 319, 310, 318, 315, 313, 315, 311, 313)
sample2 = c(335, 339, 332, 331, 334, 339, 334, 318, 315, 331, 317, 330, 325)

welch_2samp = t.test(x = sample1, y = sample2,
                     mu = 0)
welch_2samp
```
Earlier, we saw a one sample Z test. This can also be extended to two samples similar to how we carried out the T test.

```{r}
sd(sample1)
sd(sample2)
res2 = z.test(x = sample1, y = sample2,
              sigma.x = 3, sigma.y = 8,
              alternative = "two.sided")
res2
```
While Z tests are "ideal", real life data is messy, so T tests are often used in practice due to the nature of having small sample sizes/unknown standard deviations, etc.

<br>

### Hypothesis Testing for Two Proportions

Assuming we have two-sample proportions, this test can be used to compare between the two proportions.

Here, we test the hypotheses: \
H0: p1 = p2 \
HA: p1 != p2 \

```{r}
x1 = 56
n1 = 200
x2 = 34
n2 = 180

p1 = x1/n1
p2 = x2/n2

paste(p1, sep = ",", round(p2, 2))

samp2_prop = prop.test(c(x1, x2), c(n1, n2))
samp2_prop
```

Now here are some more practical and advanced hypothesis tests that can be carried out to provide a more robust analysis for statistical inference.

<br>

### Chi Square test for Independence of Categorical Data

Chi Square tests are ideal for categorical data and for testing the independence between two variables. Usually, the following hypotheses are tested: \
H0: Variables A and B are independent. \
HA: variables A and B are dependent. \

Let's consider a simple example with a two by two contingency table. Here, we test: \
H0: Gender and Product Preference are independent. \
HA: Gender and Product Preference are dependent. \

```{r}
# Form a contingency table to represent our example dataset.

data = matrix(c(30, 10, 20, 40), nrow = 2,
              byrow = TRUE,
              dimnames = list(Gender = c("Male", "Female"),
      Preference = c("Product A", "Product B")))
```

```{r}
chisq.test(data)
```
Therefore, since the p-value is less than 0.05, we reject H0 and conclude that gender and product preference are dependent.

<br>

### Shapiro-Wilkes Test for Normality

This is a common hypothesis test to determine the normality of statistical distributions. We test against the hypotheses: \
H0: The dataset is normally distributed. \
HA: The dataset is not normally distributed. \

```{r}
data(mtcars)

mpg_norm = shapiro.test(mtcars$mpg)
mpg_norm

cyl_norm = shapiro.test(mtcars$cyl)
cyl_norm
```
Since the p-value is greater than 0.05, we fail to reject H0 and conclude that mpg is normally distributed. 

Since the p-value is less than 0.05, we reject H0 and conclude that cyl is not normally distributed.

Note that this test works on numeric columns, not categorical ones.

<br>

### The Power of a Statistical Test

When doing hypothesis testing, there are two types of errors: \
1. Type I: Rejecting the null when it is actually true (false positive) \
2. Type II: Not rejecting a false null hypothesis (false negative) \

Sometimes, we may want to see how "good" our test is by looking at the power function of a hypothesis test. This means we must take a look at the probabilities of correctly rejecting the null hypothesis for different parameter values. Let's revisit the Z test from earlier and plot the power function curve.

```{r}

mu0 = 100
sigma = 15
n = 25
alpha = 0.05

# Compute the critical value for the rejection region.

z_alpha = qnorm(1 - alpha)
x_crit = mu0 + z_alpha * sigma /sqrt(n)

# Generate a sequence vector of true parameter values.

mu_true = seq(100, 120, by=0.5)

# Compute the power function. 

power = 1 - pnorm((x_crit - mu_true) / (sigma / sqrt(n)))

# Plot the power function for the mu_true values we generated earlier.

plot(mu_true, power, type = "l",
     lwd = 2, col = "red",
     xlab = expression("True Mean " * mu),
     ylab = "Power",
     main = "Power Function of 1 Sample Z Test")
abline(h = alpha, col = "red", lty = 2)


```

Clearly, this is a right-tailed Z test testing the hypotheses: \
H0: mu = 100 \
HA: mu > 100 \
at the 0.05 significance level. The power function here is telling us about how sensitive our test is for correctly rejecting the null hypothesis for increasing values of the true parameter. Notice that when this happens, the power of our test increases and thus is a good way of visualizing the effectiveness of our test.

```{r}
data(iris)
library(tidyverse)

ggplot(data=iris, mapping = aes(x = Species, fill = Species)) +
  geom_bar()
```

<br>